---
title: "What is an Agent?"
description: "Learn about stateful agents in Modus"
"og:title": "What is an Agent? - Modus"
---

## Agents in Modus

Agents in Modus are elite operatives that maintain persistent memory across
missions. Unlike stateless functions that lose everything when operations end,
agents remember every detail, survive system failures, and never lose their
operational context.

## Key characteristics

- **Stateful**: Maintains memory and context across interactions
- **Persistent**: Automatically saves and restores state
- **Resilient**: Graceful recovery from failures
- **Autonomous**: Can operate independently over extended periods
- **Actor-based**: Each agent instance runs in isolation

## When to deploy agents

Agents are perfect for:

- **Multi-turn workflows** spanning multiple interactions
- **Long-running processes** that maintain context over time
- **Stateful operations** that need to remember previous actions
- **Complex coordination** between different system components
- **Persistent monitoring** that tracks changes over time

## Agent structure

Every agent starts with the essential operational framework:

```go
package main

import (
    "fmt"
    "strings"
    "time"
    "github.com/hypermodeinc/modus/sdk/go/pkg/agents"
    "github.com/hypermodeinc/modus/sdk/go/pkg/models"
    "github.com/hypermodeinc/modus/sdk/go/pkg/models/openai"
)

type IntelligenceAgent struct {
    agents.AgentBase

    briefings   []string  // Intelligence history
    confidence  float64   // Analytical confidence
    lastContact time.Time
}

func (i *IntelligenceAgent) Name() string {
    return "IntelligenceAgent"
}
```

The agent embeds `agents.AgentBase`, which provides all the infrastructure for
state management, secure communications, and mission persistence. Your
operational data—intelligence briefings, confidence metrics, contact logs—lives
as fields in the struct, automatically preserved across all interactions.

## Spawning agents through functions

Agents are deployed through regular Modus functions that become part of your
GraphQL API. These deployment functions create and manage agent instances on
demand:

```go
// Register your agent type during initialization
func init() {
    agents.Register(&IntelligenceAgent{})
}

// Deploy a new agent instance - this becomes a GraphQL mutation
func DeployAnalyst() (string, error) {
    agentInfo, err := agents.Start("IntelligenceAgent")
    if err != nil {
        return "", err
    }

    // Return the agent ID - clients must store this to communicate with the agent
    return agentInfo.Id, nil
}
```

When you call this function through GraphQL, it returns a unique agent ID:

```graphql
mutation {
  deployAnalyst
}

# Returns: "agent_abc123xyz"
```

You can think of an Agent as a persistent server process with durable memory.
Once deployed, you can reference your agent by its ID across sessions, page
reloads, and even system restarts. The agent maintains its complete state and
continues operating exactly where it left off.

<Note>
  **Agent builders and visual workflows:** We're actively developing Agent
  Builder tools and "eject to code" feature that generates complete agent
  deployments from visual workflows. These tools automatically create the
  deployment functions and agent management code for complex multi-agent
  systems.
</Note>

## Communicating with your agent

Once deployed, you communicate with your agent using its unique ID. Create
functions that send messages to specific agent instances:

```go
func SubmitIntelligence(agentId string, data string) (string, error) {
    result, err := agents.SendMessage(
        agentId,
        "analyze_intelligence",
        agents.WithData(data),
    )
    if err != nil {
        return "", err
    }
    if result == nil {
        return "", fmt.Errorf("no response from agent")
    }
    return *result, nil
}

func GetThreatAssessment(agentId string) (string, error) {
    result, err := agents.SendMessage(agentId, "threat_assessment", nil)
    if err != nil {
        return "", err
    }
    if result == nil {
        return "", fmt.Errorf("no response from agent")
    }
    return *result, nil
}
```

These functions become GraphQL mutations that you can call with your agent's ID:

```graphql
mutation {
  submitIntelligence(
    agentId: "agent_abc123xyz"
    data: "Suspicious network activity detected"
  )
}

query {
  getThreatAssessment(agentId: "agent_abc123xyz")
}
```

The agent receives the message, processes it using its internal state and AI
reasoning, updates its intelligence database, and returns a response—all while
maintaining persistent memory of every interaction.

## Agent message handling

Agents process operational directives through their secure message handling
system:

```go
func (i *IntelligenceAgent) OnReceiveMessage(
    msgName string,
    data *string,
) (*string, error) {
    switch msgName {
    case "analyze_intelligence":
        return i.analyzeIntelligence(data)
    case "threat_assessment":
        return i.getThreatAssessment()
    case "intelligence_history":
        return i.getIntelligenceHistory()
    default:
        return nil, fmt.Errorf("unrecognized directive: %s", msgName)
    }
}
```

Each directive triggers specific operational procedures, with all intelligence
automatically maintained in the agent's secure memory.

## Processing operations with AI intelligence

Here's how agents handle field operations while maintaining persistent state and
using AI models for analysis:

```go
func (i *IntelligenceAgent) analyzeIntelligence(
    data *string,
) (*string, error) {
    if data == nil {
        return nil, fmt.Errorf("no intelligence data provided")
    }

    // Store new intelligence in persistent memory
    i.briefings = append(i.briefings, *data)
    i.lastContact = time.Now()

    // Build context from all accumulated intelligence
    context := strings.Join(i.briefings, "\n")

    // AI analysis using complete operational history
    model, _ := models.GetModel[openai.ChatModel]("analyst-model")

    systemPrompt := `You are an intelligence analyst.
        Analyze patterns from accumulated briefings
        and provide threat assessment.`

    userPrompt := fmt.Sprintf(`All Intelligence:
        %s

        Provide threat assessment:`,
        context)

    input, _ := model.CreateInput(
        openai.NewSystemMessage(systemPrompt),
        openai.NewUserMessage(userPrompt),
    )

    output, _ := model.Invoke(input)
    analysis := output.Choices[0].Message.Content

    // Update confidence based on data volume
    i.confidence = float64(len(i.briefings)) / 10.0
    if i.confidence > 1.0 {
        i.confidence = 1.0
    }

    result := fmt.Sprintf(`Analysis complete:
        %s

        (Confidence: %.2f based on %d briefings)`,
        analysis,
        i.confidence,
        len(i.briefings))
    return &result, nil
}

func (i *IntelligenceAgent) getThreatAssessment() (*string, error) {
    if len(i.briefings) == 0 {
        result := `No intelligence processed yet.
            Deploy to field for analysis.`
        return &result, nil
    }

    result := fmt.Sprintf(`Current threat assessment:
        %d briefings analyzed.

        Confidence level: %.2f.
        Agent operational.`,
        len(i.briefings),
        i.confidence)
    return &result, nil
}
```

What makes this operationally superior:

- No transmission of massive state files on every contact
- No reconstruction of intelligence history from scratch
- AI models see complete operational context, not just current input
- No risk of losing analytical data during communication failures
- Intelligence quality improves with each briefing processed

The agent maintains its complete operational state and intelligence database in
secure memory, accessing it instantly when processing new directives and
invoking AI models.

## The power of intelligent persistence

This combination creates agents that:

<Note>
  **First Analysis:** "New threat detected. Limited context available.
  (Confidence: 0.10 based on 1 briefing)"
</Note>

<Note>
  **After Multiple Briefings:** "Pattern confirmed across 5 previous incidents.
  This matches Advanced Persistent Threat signatures. Immediate escalation
  recommended. (Confidence: 0.85 based on 8 briefings)"
</Note>

The agent doesn't just remember—it **learns and becomes more intelligent with
every interaction**. AI models see the complete operational picture, enabling
sophisticated pattern recognition impossible with stateless functions.

## State persistence

Agents automatically preserve their operational state through Modus's built-in
intelligence management:

```go
func (i *IntelligenceAgent) GetState() *string {
    briefingsData := strings.Join(i.briefings, "|")
    state := fmt.Sprintf("%.2f|%s|%d",
        i.confidence,
        briefingsData,
        i.lastContact.Unix())
    return &state
}

func (i *IntelligenceAgent) SetState(data *string) {
    if data == nil {
        return
    }

    parts := strings.Split(*data, "|")
    if len(parts) >= 3 {
        i.confidence, _ = strconv.ParseFloat(parts[0], 64)
        if parts[1] != "" {
            i.briefings = strings.Split(parts[1], "|")
        }
        timestamp, _ := strconv.ParseInt(parts[2], 10, 64)
        i.lastContact = time.Unix(timestamp, 0)
    }
}
```

## Agent lifecycle

Agents have built-in operational protocols for mission continuity:

```go
func (i *IntelligenceAgent) OnInitialize() error {
    // Called when agent is first deployed to the field
    i.lastContact = time.Now()
    i.confidence = 0.0
    fmt.Printf(`Intelligence Agent %s deployed
        and ready for analysis`, i.Id())
    return nil
}

func (i *IntelligenceAgent) OnResume() error {
    // Called when agent reestablishes contact with complete intel intact
    fmt.Printf(`Agent back online.
        %d briefings processed.
        Confidence level: %.2f`,
        len(i.briefings),
        i.confidence)
    return nil
}

func (i *IntelligenceAgent) OnSuspend() error {
    // Called before agent goes dark
    return nil
}

func (i *IntelligenceAgent) OnTerminate() error {
    // Called before final extraction
    fmt.Printf(`Agent %s extracted.
        Intelligence archive preserved.`, i.Id())
    return nil
}
```

## Agent workflow example

1. Client calls `DeployAnalyst()` → receives agent ID `"agent_12345"`
2. Client stores `"agent_12345"` for future communications
3. Client calls `SubmitIntelligence("agent_12345", "network anomaly detected")`
   → agent stores data and uses AI to analyze patterns from complete
   intelligence history
4. Agent invokes AI model with accumulated context → generates sophisticated
   threat assessment based on all previous briefings
5. Client calls `GetThreatAssessment("agent_12345")` → agent returns AI-powered
   analysis from persistent memory
6. Agent persists across system restarts, maintaining complete intelligence
   database and learned patterns

**Important**: clients must store the agent ID returned from deployment
functions to communicate with that specific agent instance. Each agent maintains
its own independent state and can only be accessed through its unique ID.

## Beyond simple operations

Agents enable sophisticated operational patterns impossible with stateless
functions:

- **Operational continuity**: Maintain mission state across system failures and
  re-deployments
- **Intelligence building**: Accumulate understanding across multiple
  assignments through AI-powered analysis
- **Mission recovery**: Resume operations from last secure checkpoint instead of
  starting over
- **Network coordination**: Manage complex multi-agent operations with shared
  intelligence
- **Adaptive learning**: AI models become more effective as agents accumulate
  operational data

Agents represent the evolution from stateless functions to elite operatives that
maintain complete operational continuity and build intelligence over time.
They're the foundation for building intelligence networks that never lose track
of their missions and become smarter with every interaction, no matter what
happens in the field.
