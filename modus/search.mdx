---
title: Search
description: "Adding search function to your app"
---

The Modus Collections API enables developers to store, retrieve, and search data within collections using both natural language and vector-based search methods.

## Prerequisites

Before implementing search, ensure you have [defined a collection in the manifest](../app-manifest#collections) and have a working Hypermode setup.

### Understanding Key Components

- **Collections**: A **collection** is a structured storage that organizes and stores textual data and associated metadata, such as vectors or labels.
  Collections enable sophisticated search, retrieval, and classification tasks using embeddings and vectors.

In this example, `myProducts` is the collection used to store product descriptions.

- **Search Methods**: A **search methods** is associated with a collection. It defines how to convert collection's items into a vector representation and provides indexing parameters.

- **Vetor embedding**: In order to be used for vector-based search and comparison, each item in the collection must be converted into a vector representation called **embedding**. By embedding data, you enable powerful natural language and similarity-based searches.
  <Note>
    Modus runtime automatically compute the embeddings, according to your
    configuration, when items are added or updated.
  </Note>

# Configure your search method

The search functionality relies on a search method and embedding function. To configure your search method

- create an embedding function

- declare a [search method](../app-manifest#collections-properties) in the application manifest

## Create an embedding function

An embedding function is any API function that transforms text into vectors that represent their meaning in a high-dimensional space.

Embeddings functions must have the following signature

<CodeGroup>

```ts AssemblyScript
export function embed(text: string[]): f32[][] {
  ...
}
```

```go Go
package main

func Embed(text []string) ([][]float32, error) {
  ...
}

```

</CodeGroup>

Embeddings are usually computed using an embedding models. Here are few examples

### Compute embedding with Hugging face [all-MiniLM-L6-v2](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2){target="\_blank"},

[Declare the model]([search method](../app-manifest#models) in the application manifest

```json
  "models": {
    // This defines a model hosted on Hypermode
    // that can be used for vector embeddings.
    "minilm": {
      "sourceModel": "sentence-transformers/all-MiniLM-L6-v2",
      "provider": "hugging-face",
      "host": "hypermode" //Specify "hypermode" for models deployed by Hypermode
    }
  }
```

Create the embedding function using the embedding model:

<CodeGroup>

```ts AssemblyScript
import { models } from "@hypermode/functions-as";
import { EmbeddingsModel } from "@hypermode/models-as/models/experimental/embeddings";

export function embed(texts: string[]): f32[][] {
  // "minilm" is the model name declared in the application manifest

  const model = models.getModel<EmbeddingsModel>("minilm");
  const input = model.createInput(texts);
  const output = model.invoke(input);
  return output.predictions;
}
```

```go Go
package main

import (
	"github.com/hypermodeAI/functions-go/pkg/models"
	"github.com/hypermodeAI/functions-go/pkg/models/experimental"
)

func Embed(text []string) ([][]float32, error) {
    model, err := models.GetModel[experimental.EmbeddingsModel]("minilm")
    // "minilm" is the model name declared in the application manifest
    if err != nil {
        return nil, err
    }

    input, err := model.CreateInput(text...)
    if err != nil {
        return nil, err
    }
    output, err := model.Invoke(input)
    if err != nil {
        return nil, err
    }
    return output.Predictions, nil
}

```

</CodeGroup>

### Compute embedding using OpenAI embedding model

[Declare the model]([search method](../app-manifest#models) in the application manifest

```json
  "models": {
    // This defines a model hosted on OpenAI that can be used for vector embeddings.
    "openai-embeddings": {
      "sourceModel": "text-embedding-3-small",
      "host": "openai",
      "path": "v1/embeddings"
    }
  },
  "hosts": {
    // This defines the OpenAI host, which is used by the OpenAI embeddings model above.
    // The {{API_KEY}} will be replaced by the secret provided in the Hypermode Console.
    "openai": {
      "baseUrl": "https://api.openai.com/",
      "headers": {
        "Authorization": "Bearer {{API_KEY}}"
      }
    }
  }
```

Create the embedding function using the embedding model:

<CodeGroup>

```ts AssemblyScript
export function embed(text: string[]): f32[][] {
  const model = models.getModel<OpenAIEmbeddingsModel>("openai-embeddings");
  // "openai-embeddings is the model name declared in the application manifest
  const input = model.createInput(text);
  const output = model.invoke(input);
  return output.data.map<f32[]>((d) => d.embedding);
}
```

```go Go
package main

import (
	"github.com/hypermodeAI/functions-go/pkg/models"
	"github.com/hypermodeAI/functions-go/pkg/models/experimental"
)

func Embed(texts ...string) ([][]float32, error) {
	// Retrieve the model for OpenAI embeddings
    // "openai-embeddings is the model name declared in the application manifest
	model, err := models.GetModel[openai.EmbeddingsModel]("openai-embeddings")
	if err != nil {
		return nil, fmt.Errorf("failed to get OpenAI embeddings model: %w", err)
	}

	// Create input for the model using the provided texts
	input, err := model.CreateInput(texts)
	if err != nil {
		return nil, fmt.Errorf("failed to create input for OpenAI embeddings: %w", err)
	}

	// Invoke the model with the generated input
	output, err := model.Invoke(input)
	if err != nil {
		return nil, fmt.Errorf("failed to invoke OpenAI embeddings model: %w", err)
	}

	// Prepare the result slice based on the size of the output data
	results := make([][]float32, len(output.Data))

	// Copy embeddings from output into the result slice
	for i, d := range output.Data {
		results[i] = d.Embedding
	}

	return results, nil
}
```

</CodeGroup>

### Declare the search method

With an embedding function in place, declare a search method in the [collection properties](../app-manifest#collections-properties)

```json
  "collections": {
    // This defines a collection of products
    "myProducts": {
        "searchMethods": {
            "searchMethod1": {
                "embedder": "embed" // embedding function name
            }
        }
    }
  }

```

## Add Items to the Collection

First, we need to populate the collection with items (e.g., product descriptions). You can insert individual or multiple items using the [collections.upser](../sdk/collections.mdx#upsert) and [collections.upsertBatch](../sdk/collections.mdx#upsertbatch) methods, respectively.

Use [collections.upsert](../sdk/collections.mdx#upsert) to insert a product description into the collection. If you don't specify a key, a unique key will be generated for you.

<CodeGroup>

```ts AssemblyScript
export function addProduct(description: string): string {
  const response = collections.upsert(
    "myProducts", // Collection name defined in the manifest
    null, // using null to let Modus generate a unique ID
    description, // the text to store
    // no labels for this item
    // no namespace provided, use defautl namespace
  );
  return response.keys[0]; // return the identifier of the item
}
```

```go Go
func AddProduct(description string) ([]string, error) {
	res, err := collections.Upsert(
        "myProducts",  // Collection name defined in the manifest
        nil,           // using nil to let Modus generate a unique ID
        description,   // the text to store
        nil            // we don't have labels for this item
        )
	if err != nil {
		return nil, err
	}
	return res.Keys, nil
}
```

</CodeGroup>

To add a batch of product descriptions, use the [collections.upsertBatch](../sdk/collections.mdx#upsertbatch) method.

## Implement Natural Language Search

With the products stored, you can now search the collection by semantic similarity. The [collections.search](../sdk/collections.mdx#search) api computes an embedding for the provided text, compares it with the embeddings of the items in the collection, and returns the most similar items.

```ts
export function searchProducts(
  product_description: string,
  maxItems: i32,
): collections.CollectionSearchResult[] {
  const responseArr: collections.CollectionSearchResult[] = [];
  const searchMethods = ["searchMethod1", "searchMethod2"]; // defined search methods

  const response = collections.search(
    "myProducts", // collection name declated in the application manifest
    "searchMethod1", // search method declared for this collection in the manifest
    product_description, // text to search for
    maxItems,
    true, //  returnText: bool, true to return the items text.
    // no namespace provide, use the default namespace
  );
  return response;
}
```

### Search Result Format

Each search returns an array of `CollectionSearchResult`, containing the following fields:

- `collection`: The name of the collection.
- `status`: The status of the operation (e.g., success, error).
- `objects`: The search result items with their text, distance, and score values.

```json
{
  "collection": "myProducts",
  "status": "success",
  "objects": [
    {
      "key": "item-key-123",
      "text": "Sample product description",
      "distance": 0.05,
      "score": 0.95
    }
  ]
}
```

TO DO: clarify we have a list of objects in this example and we are saying that we return a list of CollectionSearchResult. Do we have a list of list? why?
TO DO: explain distance and score range (-1 1 or 0 1 ?)

## Search by Vector

TO DO: explain why this use case is interresting instead of "if you want"
If you want to search using a vector instead of text, you can retrieve the vector associated with an item by its key, then perform a search using that vector.

```ts
export function searchProductsById(
  productId: string,
  maxItems: i32,
): collections.CollectionSearchResult[] {
  const responseArr: collections.CollectionSearchResult[] = [];
  const searchMethods = ["searchMethod1", "searchMethod2"];

  for (let i = 0; i < searchMethods.length; i++) {
    const vec = collections.getVector(
      "myProducts",
      searchMethods[i],
      productId,
    );
    const response = collections.searchByVector(
      "myProducts",
      searchMethods[i],
      vec,
      maxItems,
      true,
    );
    responseArr.push(response);
  }

  return responseArr;
}
```

This method is useful when you have an item's ID and want to find similar items in the collection by comparing vectors.

## Recomputing Search Indexes

Sometimes, you may need to recompute the embeddings for all items in the collection for a specific search method. This can be useful if you change the underlying embedding model.

```ts
export function recomputeIndexes(): Map<string, string> {
  const responseArr: Map<string, string> = new Map<string, string>();
  const searchMethods = ["searchMethod1", "searchMethod2"];

  for (let i = 0; i < searchMethods.length; i++) {
    const response = collections.recomputeSearchMethod(
      "myProducts",
      searchMethods[i],
    );
    if (!response.isSuccessful) {
      responseArr.set(searchMethods[i], response.error);
    }
    responseArr.set(searchMethods[i], response.status);
  }

  return responseArr;
}
```

## Conclusion

This guide explains how to implement natural language-based or vector similarity searches in your application. By following these steps, you can build a robust search API for any collection of text data, such as product descriptions, using the power of vector embeddings and search methods.
TO DO: conclusion, use cases and next steps (simialrity clustering ...) multiple search method, image embedding etc ...
