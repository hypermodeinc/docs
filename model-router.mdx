---
title: Model Router
description: "Iterate quickly with seamless access to the most popular models"
---

With Model Router, you can access the most popular models with a single endpoint
and bill. Experiment with new models and scale your app without worrying about
the underlying infrastructure.

## Setup

Getting started with Model Router is simple. Generate an API key and drop it
into your favorite framework.

### Generate API key

API keys for Model Router are generated within your workspace. Generate a key by
[logging into the console](https://hypermode.com/login) and navigating to
**Model router** â†’ **API keys**.

### Connect via framework

Model Router integrates easily into the most popular frameworks.

<Tabs>
  <Tab title="OpenAI SDK">
    Model Router is a drop-in replacement for OpenAI's API.
    <CodeGroup>

```python Python
import openai

# Configure with your Hypermode Workspace API key and Hypermode Model Router base url
client = openai.OpenAI(
    api_key="<YOUR_HYP_WKS_KEY>",
    base_url="https://models.hypermode.host/v1",
)

# Set up the request
response = client.chat.completions.create(
    model="meta-llama/llama-4-scout-17b-16e-instruct",
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "What is Modus?"},
    ],
    max_tokens=150,
    temperature=0.7,
)

# Print the response
print(response.choices[0].message.content)

```

```typescript TypeScript
import OpenAI from "openai"

// Configure with your Hypermode Workspace API key and Hypermode Model Router base url
const client = new OpenAI({
  apiKey: "<YOUR_HYP_WKS_KEY>",
  baseURL: "https://models.hypermode.host/v1",
})

async function generateCompletion() {
  try {
    // Set up the request
    const response = await client.chat.completions.create({
      model: "meta-llama/llama-4-scout-17b-16e-instruct",
      messages: [
        { role: "system", content: "You are a helpful assistant." },
        { role: "user", content: "What is Modus?" },
      ],
      max_tokens: 150,
      temperature: 0.7,
    })

    // Print the response
    console.log(response.choices[0].message.content)
  } catch (error) {
    console.error("Error:", error)
  }
}

// Call the function
generateCompletion()
```

  </CodeGroup>

  </Tab>
  <Tab title="Vercel AI SDK">

```typescript
import { createOpenAI } from "@ai-sdk/openai"
import { generateText } from "ai"

// Configure with your Hypermode Workspace API key and Hypermode Model Router base url
const hypermode = createOpenAI({
  name: "hypermode",
  apiKey: "<YOUR_HYP_WKS_KEY>",
  baseURL: "https://models.hypermode.host/v1",
})

async function generateHoliday() {
  try {
    const { text, usage, providerMetadata } = await generateText({
      model: hypermode("o3-mini"),
      prompt: "Invent a new holiday and describe its traditions.",
      providerOptions: { hypermode: { reasoningEffort: "low" } },
    })

    // Print the response
    console.log(text)
    return { text, usage, providerMetadata }
  } catch (error) {
    console.error("Error generating text:", error)
    throw error
  }
}

// Call the function
generateHoliday()
```

  </Tab>
  <Tab title="Modus">

To use the Model Router in a Modus app, in your
[app manifest](/modus/app-manifest) create a connection to the Model Router and
add a model that references that connection.

```json modus.json {11-16}
{
    ...
  "models": {
    "meta-llama-llama-4-scout-17b-16e-instruct": {
      "sourceModel": "meta-llama/llama-4-scout-17b-16e-instruct",
      "connection": "model-router",
      "path": "v1/chat/completions"
    },
  },
  "connections": {
    "model-router": {
      "type": "http",
      "baseUrl": "https://models.hypermode.host/",
      "headers": {
        "Authorization": "Bearer {{YOUR_HYP_WKS_KEY}}"
      }
    }
  },
  ...
}
```

</Tab>
</Tabs>

### Connect directly via API

You can also access the API directly.

<CodeGroup>

```python Python
import requests
import json

# Your Hypermode Workspace API key
api_key = "<YOUR_HYP_WKS_KEY>"

# Use the Hypermode Model Router base url
base_url = "https://models.hypermode.host/v1"

# API endpoint
endpoint = f"{base_url}/chat/completions"

# Headers
headers = {"Content-Type": "application/json", "Authorization": f"Bearer {api_key}"}

# Request payload
payload = {
  "model": "meta-llama/llama-4-scout-17b-16e-instruct",
  "messages": [
      {"role": "system", "content": "You are a helpful assistant."},
      {"role": "user", "content": "What is Dgraph?"},
  ],
  "max_tokens": 150,
  "temperature": 0.7,
}

# Make the API request
response = requests.post(endpoint, headers=headers, data=json.dumps(payload))

# Check if the request was successful
if response.status_code == 200:
  # Parse and print the response
  response_data = response.json()
  print(response_data["choices"][0]["message"]["content"])
else:
  # Print error information
  print(f"Error: {response.status_code}")
  print(response.text)
```

```typescript TypeScript
// Define types for API responses
interface ChatCompletionChoice {
  message: {
    role: string
    content: string
  }
  index: number
  finish_reason: string
}

interface ChatCompletionResponse {
  id: string
  object: string
  created: number
  model: string
  choices: ChatCompletionChoice[]
  usage: {
    prompt_tokens: number
    completion_tokens: number
    total_tokens: number
  }
}

async function callOpenAI(): Promise<void> {
  // Your Hypermode Workspace API key
  const apiKey = "<YOUR_HYP_WKS_KEY>"

  // Use the Hypermode Model Router base url
  const baseUrl = "https://models.hypermode.host/v1"

  // API endpoint
  const endpoint = `${baseUrl}/chat/completions`

  // Request payload
  const payload = {
    model: "meta-llama/llama-4-scout-17b-16e-instruct",
    messages: [
      { role: "system", content: "You are a helpful assistant." },
      { role: "user", content: "What is Dgraph?" },
    ],
    max_tokens: 150,
    temperature: 0.7,
  }

  try {
    // Make the API request
    const response = await fetch(endpoint, {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        Authorization: `Bearer ${apiKey}`,
      },
      body: JSON.stringify(payload),
    })

    // Check if the request was successful
    if (response.ok) {
      // Parse and print the response
      const responseData: ChatCompletionResponse = await response.json()
      console.log(responseData.choices[0].message.content)
    } else {
      // Print error information
      console.error(`Error: ${response.status}`)
      console.error(await response.text())
    }
  } catch (error) {
    console.error("Request failed:", error)
  }
}

// Call the function
callOpenAI()
```

```go Go
package main

import (
  "bytes"
  "encoding/json"
  "fmt"
  "io"
  "net/http"
  "os"
)

// Define structs for the request and response
type Message struct {
  Role    string `json:"role"`
  Content string `json:"content"`
}

type ChatCompletionRequest struct {
  Model       string    `json:"model"`
  Messages    []Message `json:"messages"`
  MaxTokens   int       `json:"max_tokens"`
  Temperature float64   `json:"temperature"`
}

type ChatCompletionChoice struct {
  Message      Message `json:"message"`
  Index        int     `json:"index"`
  FinishReason string  `json:"finish_reason"`
}

type Usage struct {
  PromptTokens     int `json:"prompt_tokens"`
  CompletionTokens int `json:"completion_tokens"`
  TotalTokens      int `json:"total_tokens"`
}

type ChatCompletionResponse struct {
  ID      string                 `json:"id"`
  Object  string                 `json:"object"`
  Created int64                  `json:"created"`
  Model   string                 `json:"model"`
  Choices []ChatCompletionChoice `json:"choices"`
  Usage   Usage                  `json:"usage"`
}

func main() {
  // Your Hypermode Workspace API key
  apiKey := "<YOUR_HYP_WKS_KEY>"

  // Use the Hypermode Model Router base url
  baseURL := "https://models.hypermode.host/v1"

  // API endpoint
  endpoint := baseURL + "/chat/completions"

  // Create the request payload
  requestBody := ChatCompletionRequest{
    Model: "meta-llama/llama-4-scout-17b-16e-instruct",
    Messages: []Message{
      {
        Role:    "system",
        Content: "You are a helpful assistant.",
      },
      {
        Role:    "user",
        Content: "What is Dgraph?",
      },
    },
    MaxTokens:   150,
    Temperature: 0.7,
  }

  // Convert the request to JSON
  jsonData, err := json.Marshal(requestBody)
  if err != nil {
    fmt.Printf("Error marshaling JSON: %v\n", err)
    os.Exit(1)
  }

  // Create an HTTP request
  req, err := http.NewRequest("POST", endpoint, bytes.NewBuffer(jsonData))
  if err != nil {
    fmt.Printf("Error creating request: %v\n", err)
    os.Exit(1)
  }

  // Set headers
  req.Header.Set("Content-Type", "application/json")
  req.Header.Set("Authorization", "Bearer "+apiKey)

  // Create an HTTP client and send the request
  client := &http.Client{}
  resp, err := client.Do(req)
  if err != nil {
    fmt.Printf("Error sending request: %v\n", err)
    os.Exit(1)
  }
  defer resp.Body.Close()

  // Read the response body
  body, err := io.ReadAll(resp.Body)
  if err != nil {
    fmt.Printf("Error reading response: %v\n", err)
    os.Exit(1)
  }

  // Check if the request was successful
  if resp.StatusCode == http.StatusOK {
    // Parse and print the response
    var response ChatCompletionResponse
    err = json.Unmarshal(body, &response)
    if err != nil {
      fmt.Printf("Error parsing response: %v\n", err)
      os.Exit(1)
    }

    fmt.Println(response.Choices[0].Message.Content)
  } else {
    // Print error information
    fmt.Printf("Error: %d\n", resp.StatusCode)
    fmt.Println(string(body))
  }
}

```

</CodeGroup>

## Available models

Hypermode provides a variety of the most popular open source and commercial
models.

<Note>
  We're constantly evaluating model usage in determining new models to add to
  our catalog. Interested in using a model not listed here? Let us know at
  [help@hypermode.com](mailto:help@hypermode.com).
</Note>

### Generation

Large language models provide text generation and reasoning capabilities.

| Provider  | Model                                  | Slug                                        |
| --------- | -------------------------------------- | ------------------------------------------- |
| Anthropic | Claude 3.7 Sonnet                      | `claude-3-7-sonnet-20250219`                |
| Anthropic | Claude 3.5 Sonnet (latest)             | `claude-3-5-sonnet-20241022`                |
| Anthropic | Claude 3.5 Sonnet                      | `claude-3-5-sonnet-20240620`                |
| Anthropic | Claude 3.5 Sonnet                      | `claude-3-5-sonnet-20240229`                |
| Anthropic | Claude 3.5 Haiku (latest)              | `claude-3-5-haiku-20241022`                 |
| Anthropic | Claude 3.5 Haiku                       | `claude-3-5-haiku-20240307`                 |
| Anthropic | Claude 3.5 Opus                        | `claude-3-5-opus-20240229`                  |
| Anthropic | Claude 2.1                             | `claude-2.1`                                |
| Anthropic | Claude 2.0                             | `claude-2.0`                                |
| DeepSeek  | DeepSeek-R1-Distill-Llama              | `deepseek-ai/deepseek-r1-distill-llama-8b`  |
| Google    | Gemini 2.5 Pro                         | `gemini-2.5-pro-exp-03-25`                  |
| Google    | Gemini 2.5 Pro Preview                 | `gemini-2.5-pro-preview-03-25`              |
| Google    | Gemini 2.5 Flash Preview               | `gemini-2.5-flash-preview-04-17`            |
| Google    | Gemini 2.0 Pro                         | `gemini-2.0-pro-exp-02-05`                  |
| Google    | Gemini 2.0 Flash Lite (latest)         | `gemini-2.0-flash-lite`                     |
| Google    | Gemini 2.0 Flash Lite                  | `gemini-2.0-flash-lite-001`                 |
| Google    | Gemini 2.0 Flash Lite Preview (latest) | `gemini-2.0-flash-lite-preview-02-05`       |
| Google    | Gemini 2.0 Flash Lite Preview          | `gemini-2.0-flash-lite-preview`             |
| Google    | Gemini 2.0 Flash Image Generation      | `gemini-2.0-flash-exp-image-generation`     |
| Google    | Gemini 2.0 Flash Thinking (latest)     | `gemini-2.0-flash-thinking-exp`             |
| Google    | Gemini 2.0 Flash Thinking              | `gemini-2.0-flash-thinking-exp-1219`        |
| Google    | Gemini 2.0 Flash Thinking              | `gemini-2.0-flash-thinking-exp-01-21`       |
| Google    | Gemini 2.0 Flash Live                  | `gemini-2.0-flash-live-001`                 |
| Google    | Gemini 2.0 Flash (latest)              | `gemini-2.0-flash`                          |
| Google    | Gemini 2.0 Flash                       | `gemini-2.0-flash-001`                      |
| Google    | Gemini 2.0 Flash                       | `gemini-2.0-flash-exp`                      |
| Google    | Gemini 1.5 Pro (latest)                | `gemini-1.5-pro-latest`                     |
| Google    | Gemini 1.5 Pro                         | `gemini-1.5-pro`                            |
| Google    | Gemini 1.5 Pro                         | `gemini-1.5-pro-002`                        |
| Google    | Gemini 1.5 Pro                         | `gemini-1.5-pro-001`                        |
| Google    | Gemini 1.5 Flash (latest)              | `gemini-1.5-flash-latest`                   |
| Google    | Gemini 1.5 Flash                       | `gemini-1.5-flash`                          |
| Google    | Gemini 1.5 Flash                       | `gemini-1.5-flash-002`                      |
| Google    | Gemini 1.5 Flash                       | `gemini-1.5-flash-001`                      |
| Google    | Gemini 1.5 Flash 8B (latest)           | `gemini-1.5-flash-8b-latest`                |
| Google    | Gemini 1.5 Flash 8B                    | `gemini-1.5-flash-8b`                       |
| Google    | Gemini 1.5 Flash 8B                    | `gemini-1.5-flash-8b-exp-0924`              |
| Google    | Gemini 1.5 Flash 8B                    | `gemini-1.5-flash-8b-exp-0827`              |
| Google    | Gemini 1.5 Flash 8B                    | `gemini-1.5-flash-8b-001`                   |
| Google    | Gemini Pro Vision                      | `gemini-pro-vision`                         |
| Meta      | Llama 4 Scout                          | `meta-llama/llama-4-scout-17b-16e-instruct` |
| Meta      | Llama 3.2                              | `meta-llama/llama-3.2-3b-instruct`          |
| OpenAI    | GPT 4.5 Preview (latest)               | `gpt-4.5-preview`                           |
| OpenAI    | GPT 4.5 Preview                        | `gpt-4.5-preview-2025-02-27`                |
| OpenAI    | O3 Mini (latest)                       | `o3-mini`                                   |
| OpenAI    | O3 Mini                                | `o3-mini-2025-01-31`                        |
| OpenAI    | O1 (latest)                            | `o1`                                        |
| OpenAI    | O1                                     | `o1-2024-12-17`                             |
| OpenAI    | O1 Preview (latest)                    | `o1-preview`                                |
| OpenAI    | O1 Preview                             | `o1-preview-2024-09-12`                     |
| OpenAI    | O1 Mini (latest)                       | `o1-mini`                                   |
| OpenAI    | O1 Mini                                | `o1-mini-2024-09-12`                        |
| OpenAI    | GPT 4.1 (latest)                       | `gpt-4.1`                                   |
| OpenAI    | GPT 4.1                                | `gpt-4.1-2025-04-14`                        |
| OpenAI    | GPT 4.1 Mini (latest)                  | `gpt-4.1-mini`                              |
| OpenAI    | GPT 4.1 Mini                           | `gpt-4.1-mini-2025-04-14`                   |
| OpenAI    | GPT 4.1 Nano (latest)                  | `gpt-4.1-nano`                              |
| OpenAI    | GPT 4.1 Nano                           | `gpt-4.1-nano-2025-04-14`                   |
| OpenAI    | GPT 4o (latest)                        | `gpt-4o`                                    |
| OpenAI    | GPT 4o                                 | `gpt-4o-2024-11-20`                         |
| OpenAI    | GPT 4o                                 | `gpt-4o-2024-08-06`                         |
| OpenAI    | GPT 4o                                 | `gpt-4o-2024-05-13`                         |
| OpenAI    | GPT 4o Mini (latest)                   | `gpt-4o-mini`                               |
| OpenAI    | GPT 4o Mini                            | `gpt-4o-mini-2024-07-18`                    |
| OpenAI    | GPT 4o Audio Preview (latest)          | `gpt-4o-audio-preview`                      |
| OpenAI    | GPT 4o Audio Preview                   | `gpt-4o-audio-preview-2024-12-17`           |
| OpenAI    | GPT 4o Audio Preview                   | `gpt-4o-audio-preview-2024-10-01`           |
| OpenAI    | GPT 4o Search Preview (latest)         | `gpt-4o-search-preview`                     |
| OpenAI    | GPT 4o Search Preview                  | `gpt-4o-search-preview-2025-03-11`          |
| OpenAI    | GPT 4o Search Preview                  | `gpt-4o-search-preview-2025-03-11`          |
| OpenAI    | ChatGPT 4o                             | `chatgpt-4o-latest`                         |
| OpenAI    | GPT 4 (latest)                         | `gpt-4`                                     |
| OpenAI    | GPT 4                                  | `gpt-4-0613`                                |
| OpenAI    | GPT 4 Turbo                            | `gpt-4-turbo-2024-04-09`                    |
| OpenAI    | GPT 4 Turbo Preview                    | `gpt-4-turbo-preview`                       |
| OpenAI    | GPT 4 Preview (latest)                 | `gpt-4-1106-preview`                        |
| OpenAI    | GPT 4 Preview                          | `gpt-4-0125-preview`                        |
| OpenAI    | GPT 3.5 Turbo (latest)                 | `gpt-3.5-turbo`                             |
| OpenAI    | GPT 3.5 Turbo                          | `gpt-3.5-turbo-1106`                        |
| OpenAI    | GPT 3.5 Turbo                          | `gpt-3.5-turbo-0125`                        |

### Embedding

Embedding models provide vector representations of text for similarity matching
and other applications.

| Provider     | Model           | Slug                                     |
| ------------ | --------------- | ---------------------------------------- |
| Hugging Face | MiniLM-L6-v2    | `sentence-transformers/all-MiniLM-L6-v2` |
| Nomic AI     | Embed Text V1.5 | `nomic-ai/nomic-embed-text-v1.5`         |

## Logging

By default, all model invocations are logged for future display in the console.
If you'd like to opt out of model logging, please
[contact us](mailto:help@hypermode.com).
