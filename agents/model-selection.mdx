---
title: "Model Selection Guide"
sidebarTitle: "Choose the Right Model"
description:
  "Select the optimal model for your agent based on your goals and use case."
---

Choosing the right model is essential to building effective agents. This guide helps you evaluate trade-offs, pick the right model for your use case, and iterate quickly.

![Select your model](/images/agents/model-selection.png)

## Key considerations
- **Accuracy and output quality:** Advanced logic, mathematical problem-solving, and multi-step analysis may require high-capability models.
- **Domain expertise:** Performance varies by domain (e.g., creative writing, code, scientific analysis). Review model benchmarks or test with your own examples.
- **Context window:** Long documents, extensive conversations, or large codebases require models with longer context windows.
- **Embeddings:** For semantic search or similarity, consider embedding models. These are not for text generation.
- **Latency:** Real-time apps may need low-latency responses. Smaller models (or “Mini,” “Nano,” and “Flash” variants) typically respond faster than larger models.

## Models by task / use case at a glance
| Task / use case | Example models | Key strengths | Considerations |
| --- | --- | --- | --- |
| General-purpose conversation | Claude 4 Sonnet, GPT-4.1, Gemini Pro | Balanced, reliable, creative | May not handle edge cases as well |
| Complex reasoning and research | Claude 4 Opus, O3, Gemini 2.5 Pro | Highest accuracy, multi-step analysis | Higher cost, quality critical |
| Creative writing and content | Claude 4 Opus, GPT-4.1, Gemini 2.5 Pro | High-quality output, creativity, style control | High cost for premium content |
| Document analysis and summarization | Claude 4 Opus, Gemini 2.5 Pro, Llama 3.3 | Handles long inputs, comprehension | Higher cost, slower |
| Real-time apps | Claude 3.5 Haiku, GPT-4o Mini, Gemini 1.5 Flash 8B | Low latency, high throughput | Less nuanced, shorter context |
| Semantic search and embeddings | OpenAI Embedding 3, Nomic AI, Hugging Face | Vector search, similarity, retrieval | Not for text generation |
| Custom model training & experimentation | Llama 4 Scout, Llama 3.3, DeepSeek, Mistral | Open source, customizable | Requires setup, variable performance |

<Note>
Hypermode provides access to the most popular open source and commercial models through [Hypermode Model Router documentation](/model-router). We're constantly evaluating model usage and adding new models to our catalog based on demand.
</Note>

## Get started

You can change models at any time in your agent settings. Start with a general-purpose model, then iterate and optimize as you learn more about your agent’s needs.

1. [**Create an agent**](/create-agent) with GPT-4.1 (default).
2. **Define clear instructions and [connections](/connections)** for the agent's role.
3. **Test with real examples** from your workflow.
4. **Refine and iterate** based on results.
5. **Evaluate alternatives** once you understand patterns and outcomes.

<Tip>
**Value first, optimize second.** Clarify the task requirements before tuning for
specialized capabilities or cost.
</Tip>

## Comparison of select large language models

| Model | Provider | Best For | Key Strengths | Considerations | Context Window<sup>+</sup> | Speed | Cost<sup>++</sup> |
| --- | --- | --- | --- | --- | --- | --- | --- |
| **Claude 4 Opus** | Anthropic | Complex reasoning, long docs | Highest accuracy, long context, safe | Higher cost, slower than lighter models | Very long (200K+) | Moderate | $$$$ |
| **Claude 4 Sonnet** | Anthropic | General-purpose, balanced workloads | Good accuracy, fast, safe | Less capable than Opus for edge cases | Long (100K+) | Fast | $$$ |
| **GPT-4.1** | OpenAI | Most tasks, nuanced output | Reliable, creative, strong reasoning | Higher cost, moderate speed | Long (128K) | Moderate | $$$ |
| **GPT-4.1 Mini** | OpenAI | High-volume, cost-sensitive | Fast, affordable, scalable | Less nuanced, shorter context | Medium (32K–64K) | Very Fast | $$ |
| **GPT o3** | OpenAI | General chat, broad compatibility | Versatile, strong performance | May lack latest features/capabilities | Medium (32K–64K) | Fast | $$ |
| **Gemini 2.5 Pro** | Google | Up-to-date info | Long context | Limited access, higher cost | Long (128K+) | Moderate | $$$ |
| **Gemini 2.5 Flash** | Google | Real-time, rapid responses | Extremely fast, cost-effective | Shorter context, less nuanced | Medium (32K–64K) | Very Fast | $$ |
| **Llama 4 Scout** | Meta | Privacy, customization, open source | Open source, flexible deployment | Variable performance | Medium–Long (varies) | Fast | $ |

<sup>+</sup>Context window sizes are approximate and may vary by deployment/version.
<sup>++</sup>Relative cost per 1K tokens ($ = lowest, $$$$ = highest)
